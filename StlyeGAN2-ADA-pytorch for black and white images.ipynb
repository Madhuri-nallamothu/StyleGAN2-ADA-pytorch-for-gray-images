{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeTGOjTaJuJp"
      },
      "source": [
        "# This is StlyeGAN2-ADA-pytorch for gray images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Madhuri-nallamothu/StyleGAN2-ADA-pytorch-for-gray-images.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80GM4U6Af3aB",
        "outputId": "91d2c8c8-6945-47d8-c876-ec9315b67299"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'StyleGAN2-ADA-pytorch-for-gray-images' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRPibVL2rnAo",
        "outputId": "11dfe12d-43fc-40f1-cf77-3b6ecef96893"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Define input and output directories\n",
        "input_dir = \"/content/drive/MyDrive/MedicalExpert-II\"\n",
        "output_dir = \"/content/drive/MyDrive/MedicalExpert-II/grayscale_images\"\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Process all PNG files in the input directory\n",
        "for img_file in os.listdir(input_dir):\n",
        "    if img_file.endswith(\".png\"):  # Process only PNG files\n",
        "        img_path = os.path.join(input_dir, img_file)\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        # Convert to grayscale\n",
        "        gray_img = img.convert(\"L\")\n",
        "\n",
        "        # Save the grayscale image\n",
        "        gray_img.save(os.path.join(output_dir, img_file))\n",
        "\n",
        "print(\"Conversion completed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3FMprmMvu3p",
        "outputId": "0677f5a9-af8f-458b-c0a0-66fbae8c3f0e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import PIL.Image\n",
        "\n",
        "def center_crop(img):\n",
        "    # Ensure the image is a NumPy array\n",
        "    img = np.array(img)\n",
        "\n",
        "    # Convert RGB images to grayscale if needed\n",
        "    if len(img.shape) == 3:  # If image has 3 dimensions (H, W, C)\n",
        "        img = np.mean(img, axis=-1).astype(np.uint8)  # Convert to grayscale\n",
        "\n",
        "    # Now convert it to a PIL Image in grayscale mode 'L'\n",
        "    img = PIL.Image.fromarray(img, 'L')\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "GM5vtABHyU41"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "0FxgX6yeJuJ5",
        "outputId": "3ae74b40-d986-4e20-c6a8-8edb75e799d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0/1650 [00:00<?, ?it/s]\r  0% 0/1650 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StyleGAN2-ADA-pytorch-for-gray-images/dataset_tool_gray.py\", line 433, in <module>\n",
            "    convert_dataset() # pylint: disable=no-value-for-parameter\n",
            "    ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1161, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1082, in main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1443, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 788, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/decorators.py\", line 33, in new_func\n",
            "    return f(get_current_context(), *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleGAN2-ADA-pytorch-for-gray-images/dataset_tool_gray.py\", line 380, in convert_dataset\n",
            "    img = transform_image(image['img'])\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleGAN2-ADA-pytorch-for-gray-images/dataset_tool_gray.py\", line 220, in center_crop\n",
            "    img = PIL.Image.fromarray(img, 'L')\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/PIL/Image.py\", line 3326, in fromarray\n",
            "    raise ValueError(msg)\n",
            "ValueError: Too many dimensions: 3 > 2.\n"
          ]
        }
      ],
      "source": [
        "!python StyleGAN2-ADA-pytorch-for-gray-images/dataset_tool_gray.py \\\n",
        "  --source \"/content/drive/MyDrive/MedicalExpert-II\" \\\n",
        "  --dest ./dataset_folder.zip \\\n",
        "  --transform center-crop \\\n",
        "  --width 512 \\\n",
        "  --height 512\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0g4mZwvJuKS"
      },
      "source": [
        "### examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "u4PePzaCJuKT",
        "outputId": "ac7d15b6-b91c-45bf-f515-c5a8e2c021c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3: can't find '__main__' module in '/content/drive/MyDrive/MedicalExpert-II'\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/drive/MyDrive/MedicalExpert-II\" --source /path/to/source --dest /path/to/dest --transform center-crop\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w0lJs50_0pUq",
        "outputId": "00e8ca5d-d8cd-4edc-8b43-b12ad49b90d9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.2.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.5.1%2Bcu118-cp311-cp311-linux_x86_64.whl (838.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m838.4/838.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.5.1+cu118\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "e694ab0991d84b6eae8a48bce9db0356"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJg96713JuKU"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GWsNBg3JuKZ"
      },
      "source": [
        "### --dry run is for check parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NyTx4nm1JuKa",
        "outputId": "83b81eb7-7476-4df2-ffc4-a1a9ce18bb1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "Usage: train.py [OPTIONS]\n",
            "Try 'train.py --help' for help.\n",
            "\n",
            "Error: Invalid value for '--kimg': '=1000' is not a valid integer.\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "Usage: train.py [OPTIONS]\n",
            "Try 'train.py --help' for help.\n",
            "\n",
            "Error: Invalid value for '--gpus': 'N_GPU' is not a valid integer.\n"
          ]
        }
      ],
      "source": [
        "!python /content/StyleGAN2-ADA-pytorch-for-gray-images/train.py --outdir=./outdir --data=dataset_floder.zip --gpus=2 --cfg=auto --kimg =1000 --dry-run\n",
        "!python /content/StyleGAN2-ADA-pytorch-for-gray-images/train.py --outdir=./outdir--data= dataset_floder.zip --gpus=N_GPU --cfg=auto\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgLN7buFJuKa"
      },
      "source": [
        "### examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CcXBHSfYJuKa",
        "outputId": "166c96d9-4446-4a91-bffe-dca57aa4d610",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/train.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python train.py --outdir=./training-runs --data=./datasets/0323oiaclassify1.zip  --gpus=2 --cfg=auto\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHBfDgShJuKh"
      },
      "source": [
        "## Generate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2ARdl4v8JuKh",
        "outputId": "98c5a1e7-b45c-47ce-fd97-f172d754ecf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/generate_gray.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python generate_gray.py --outdir=./output_folder --seeds=number of seeds --network= path to netwrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtbSagCEJuKi"
      },
      "source": [
        "### examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4dcfjGRxJuKj",
        "outputId": "acb9c6bf-5e12-476e-c396-ad332b8b62d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/generate_gray.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python generate_gray.py --outdir=./output --seeds=0-1000 --network=./training-runs/00000-sunh-auto2-kimg1000/network-snapshot-000800.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6SHkeXwJuKj"
      },
      "source": [
        "## Calc_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "3OARL4JUJuKp",
        "outputId": "09209deb-146e-4a45-bb13-687fdeaf21d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/calc_metrics.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python calc_metrics.py --metrics=fid50k_full --data=dataset_floder.zip --mirror=1 --network= path to netwrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu75upcEJuKp"
      },
      "source": [
        "# Stlyle mixing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fIs368BXJuKp",
        "outputId": "33d50c23-33b2-46e1-86b8-f15e530b8465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/style_mixing_gray.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python style_mixing_gray.py --outdir=stylemix --rows=1,6,10,11,13,22,25,34 --cols=37,39,38,35, 29 --network= path to netwrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Uhdld6uJuKv"
      },
      "source": [
        "# Projecter\n",
        "\n",
        "Projecting images to latent space\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KtXxTYEBJuKv",
        "outputId": "013eb64a-cb19-4532-b6e8-a2702422d131",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/projector_gray.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python projector_gray.py --outdir=out --target=~/mytargetimg.png --network= path to netwrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL8OkmMYJuKv"
      },
      "source": [
        "# Make zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OuA8bi9oJuKw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "def zipdir(path, ziph):\n",
        "    # ziph is zipfile handle\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            ziph.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), os.path.join(path, '..')))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    zipf = zipfile.ZipFile('0331_class4_generated.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "    zipdir('./out0330', zipf)\n",
        "    zipf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "en2pK4p-JuK4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}